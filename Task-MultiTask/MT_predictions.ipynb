{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ecc6ed7",
   "metadata": {},
   "source": [
    "# Model predictions for the multitask model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e9b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "import statistics\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3eef5e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the data\n",
    "\n",
    "# Model predictions\n",
    "MT_TD = pd.read_csv('Predictions/MT_preds_PadChest_TD.csv', index_col=0)\n",
    "MT_PD = pd.read_csv('Predictions/MT_preds_PadChest_PD.csv', index_col=0)\n",
    "\n",
    "# True labels\n",
    "test_padchest = pd.read_csv('../Data/Data_splits/pathology_detection-test.csv', index_col=0)\n",
    "annotations = pd.read_csv('../Data/Annotations/Annotations_aggregated.csv', index_col=0)\n",
    "padchest_test_labels_ALL = pd.concat([test_padchest, annotations])   # Concatenating the tube and pathology test sets\n",
    "\n",
    "ann_labels = pd.read_csv('../Data/Data_splits/tube_detection-test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5bd4d8",
   "metadata": {},
   "source": [
    "## Area Under the ROC Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96a2d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading the predictions, which are strings, as numpy arrays\n",
    "def str2array(s):\n",
    "    # Remove space after [\n",
    "    s=re.sub('\\[ +', '[', s.strip())\n",
    "    # Replace commas and spaces\n",
    "    s=re.sub('[,\\s]+', ', ', s)\n",
    "    return np.array(ast.literal_eval(s))\n",
    "\n",
    "\n",
    "# Function to arrange preds nicely in a df\n",
    "def get_preds_multiclass_PD(orig_pred_df, true_labels_df, print_auc=True):\n",
    "    \n",
    "    pathologies = ['Effusion', 'Pneumothorax', 'Atelectasis', 'Cardiomegaly', 'Pneumonia']\n",
    "    all_preds = []\n",
    "    \n",
    "    for row_number in range(len(orig_pred_df)):\n",
    "        for p_idx, p in enumerate(pathologies):\n",
    "            preds = [[str2array(i[\"Preds_model1\"]) for idx, i in orig_pred_df.iterrows()][row_number][:,p_idx],\n",
    "                     [str2array(i[\"Preds_model2\"]) for idx, i in orig_pred_df.iterrows()][row_number][:,p_idx],\n",
    "                     [str2array(i[\"Preds_model3\"]) for idx, i in orig_pred_df.iterrows()][row_number][:,p_idx]]\n",
    "            all_preds.append(preds)\n",
    "            \n",
    "    # Constructing a df with the preds and 'true' labels\n",
    "    preds_df = pd.DataFrame(list(zip(list(true_labels_df['Effusion']),\n",
    "                                     list(true_labels_df['Pneumothorax']),\n",
    "                                     list(true_labels_df['Atelectasis']),\n",
    "                                     list(true_labels_df['Cardiomegaly']),\n",
    "                                     list(true_labels_df['Pneumonia']),\n",
    "                                     list(all_preds[0][0]),\n",
    "                                     list(all_preds[0][1]),\n",
    "                                     list(all_preds[0][2]),\n",
    "                                     list(all_preds[1][0]),\n",
    "                                     list(all_preds[1][1]),\n",
    "                                     list(all_preds[1][2]),\n",
    "                                     list(all_preds[2][0]),\n",
    "                                     list(all_preds[2][1]),\n",
    "                                     list(all_preds[2][2]),\n",
    "                                     list(all_preds[3][0]),\n",
    "                                     list(all_preds[3][1]),\n",
    "                                     list(all_preds[3][2]),\n",
    "                                     list(all_preds[4][0]),\n",
    "                                     list(all_preds[4][1]),\n",
    "                                     list(all_preds[4][2]))),\n",
    "                            columns = ['Effusion', 'Pneumothorax', 'Atelectasis', 'Cardiomegaly',\n",
    "                                       'Pneumonia', 'preds_Effusion_model1', 'preds_Effusion_model2', 'preds_Effusion_model3',\n",
    "                                       'preds_Pneumothorax_model1', 'preds_Pneumothorax_model2', 'preds_Pneumothorax_model3',\n",
    "                                       'preds_Atelectasis_model1', 'preds_Atelectasis_model2', 'preds_Atelectasis_model3',\n",
    "                                       'preds_Cardiomegaly_model1', 'preds_Cardiomegaly_model2', 'preds_Cardiomegaly_model3',\n",
    "                                       'preds_Pneumonia_model1', 'preds_Pneumonia_model2', 'preds_Pneumonia_model3'])\n",
    "\n",
    "\n",
    "    if print_auc:\n",
    "        # Computing the auc for each pathology separately\n",
    "        for p in pathologies:\n",
    "            print(p)\n",
    "            auc_list = []\n",
    "            for i in range(3):\n",
    "                #print(i+1)\n",
    "                auc = roc_auc_score(preds_df[p], preds_df['preds_' + str(p) + '_model' + str(i+1)])\n",
    "                auc_list.append(auc)\n",
    "            #print(auc_list)\n",
    "\n",
    "    #        print(\"Average AUC:\", round(sum(auc_list)/3 * 100, 5))\n",
    "            print(\"Average auc:\", round(sum(auc_list)/len(auc_list)*100, 1), \"with standard deviation:\", round(statistics.stdev(auc_list)*100,1))\n",
    "            print()\n",
    "\n",
    "    return preds_df\n",
    "\n",
    "# Function to arrange preds nicely in a df\n",
    "def get_preds_multiclass_TD(orig_pred_df, true_labels_df, print_auc=True):\n",
    "    tube_types = ['Chest_drain_tube', 'NSG_tube', 'Endotracheal_tube', 'Tracheostomy_tube']\n",
    "    all_preds = []\n",
    "    \n",
    "    for row_number in range(len(orig_pred_df)):\n",
    "        for t_idx, tube in enumerate(tube_types):\n",
    "            preds = [[str2array(i[\"Preds_model1\"]) for idx, i in orig_pred_df.iterrows()][row_number][:,t_idx],\n",
    "                     [str2array(i[\"Preds_model2\"]) for idx, i in orig_pred_df.iterrows()][row_number][:,t_idx],\n",
    "                     [str2array(i[\"Preds_model3\"]) for idx, i in orig_pred_df.iterrows()][row_number][:,t_idx]]\n",
    "            all_preds.append(preds)\n",
    "\n",
    "            \n",
    "    # Constructing a df with the preds and 'true' labels\n",
    "    preds_df = pd.DataFrame(list(zip(list(true_labels_df['Chest_drain_Ann']),\n",
    "                                     list(true_labels_df['NSG_tube_Ann']),\n",
    "                                     list(true_labels_df['Endotracheal_tube_Ann']),\n",
    "                                     list(true_labels_df['Tracheostomy_tube_Ann']),\n",
    "                                     list(true_labels_df['Chest_drain_tube']),\n",
    "                                     list(true_labels_df['NSG_tube']),\n",
    "                                     list(true_labels_df['Endotracheal_tube']),\n",
    "                                     list(true_labels_df['Tracheostomy_tube']),\n",
    "                                     list(all_preds[0][0]),\n",
    "                                     list(all_preds[0][1]),\n",
    "                                     list(all_preds[0][2]),\n",
    "                                     list(all_preds[1][0]),\n",
    "                                     list(all_preds[1][1]),\n",
    "                                     list(all_preds[1][2]),\n",
    "                                     list(all_preds[2][0]),\n",
    "                                     list(all_preds[2][1]),\n",
    "                                     list(all_preds[2][2]),\n",
    "                                     list(all_preds[3][0]),\n",
    "                                     list(all_preds[3][1]),\n",
    "                                     list(all_preds[3][2]))),\n",
    "                            columns = ['Chest_drain_Ann', 'NSG_tube_Ann', 'Endotracheal_tube_Ann', 'Tracheostomy_tube_Ann',\n",
    "                                       'Chest_drain_tube_PadChest', 'NSG_tube_PadChest', 'Endotracheal_tube_PadChest', 'Tracheostomy_tube_PadChest',\n",
    "                                       'preds_CheD_model1', 'preds_CheD_model2', 'preds_CheD_model3',\n",
    "                                       'preds_NSG_model1', 'preds_NSG_model2', 'preds_NSG_model3',\n",
    "                                       'preds_Endo_model1', 'preds_Endo_model2', 'preds_Endo_model3',\n",
    "                                       'preds_Trach_model1', 'preds_Trach_model2', 'preds_Trach_model3',])\n",
    "\n",
    "\n",
    "    ## From here, one can return the preds_df if you want to see the predictions nicely\n",
    "    \n",
    "    if print_auc:\n",
    "        # Computing the auc for each tube separately\n",
    "        print('CHEST DRAIN TUBE')\n",
    "        preds_df_tube = preds_df[preds_df['Chest_drain_Ann'] != -1]\n",
    "        auc_with_anns = [roc_auc_score(preds_df_tube['Chest_drain_Ann'], preds_df_tube['preds_CheD_model1']), roc_auc_score(preds_df_tube['Chest_drain_Ann'], preds_df_tube['preds_CheD_model2']), roc_auc_score(preds_df_tube['Chest_drain_Ann'], preds_df_tube['preds_CheD_model3'])]\n",
    "        auc_with_padchest = [roc_auc_score(preds_df_tube['Chest_drain_tube_PadChest'], preds_df_tube['preds_CheD_model1']), roc_auc_score(preds_df_tube['Chest_drain_tube_PadChest'], preds_df_tube['preds_CheD_model2']), roc_auc_score(preds_df_tube['Chest_drain_tube_PadChest'], preds_df_tube['preds_CheD_model3'])]\n",
    "        print(\"Annotations Average auc:\", round(sum(auc_with_anns)/len(auc_with_anns)*100, 1), \"with standard deviation:\", round(statistics.stdev(auc_with_anns)*100,1))\n",
    "        print(\"PadChest Average auc:\", round(sum(auc_with_padchest)/len(auc_with_padchest)*100, 1), \"with standard deviation:\", round(statistics.stdev(auc_with_padchest)*100,1))\n",
    "        #print(auc_with_anns)\n",
    "        #print(auc_with_padchest)\n",
    "        print()\n",
    "\n",
    "        print('NSG TUBE')\n",
    "        preds_df_tube = preds_df[preds_df['NSG_tube_Ann'] != -1]\n",
    "        auc_with_anns = [roc_auc_score(preds_df_tube['NSG_tube_Ann'], preds_df_tube['preds_NSG_model1']), roc_auc_score(preds_df_tube['NSG_tube_Ann'], preds_df_tube['preds_NSG_model2']), roc_auc_score(preds_df_tube['NSG_tube_Ann'], preds_df_tube['preds_NSG_model3'])]\n",
    "        auc_with_padchest = [roc_auc_score(preds_df_tube['NSG_tube_PadChest'], preds_df_tube['preds_NSG_model1']), roc_auc_score(preds_df_tube['NSG_tube_PadChest'], preds_df_tube['preds_NSG_model2']), roc_auc_score(preds_df_tube['NSG_tube_PadChest'], preds_df_tube['preds_NSG_model3'])]\n",
    "        print(\"Annotations Average auc:\", round(sum(auc_with_anns)/len(auc_with_anns)*100, 1), \"with standard deviation:\", round(statistics.stdev(auc_with_anns)*100,1))\n",
    "        print(\"PadChest Average auc:\", round(sum(auc_with_padchest)/len(auc_with_padchest)*100, 1), \"with standard deviation:\", round(statistics.stdev(auc_with_padchest)*100,1))\n",
    "        #print(auc_with_anns)\n",
    "        #print(auc_with_padchest)\n",
    "        print()\n",
    "\n",
    "        print('ENDOTRACHEAL TUBE')\n",
    "        preds_df_tube = preds_df[preds_df['Endotracheal_tube_Ann'] != -1]\n",
    "        auc_with_anns = [roc_auc_score(preds_df_tube['Endotracheal_tube_Ann'], preds_df_tube['preds_Endo_model1']), roc_auc_score(preds_df_tube['Endotracheal_tube_Ann'], preds_df_tube['preds_Endo_model2']), roc_auc_score(preds_df_tube['Endotracheal_tube_Ann'], preds_df_tube['preds_Endo_model3'])]\n",
    "        auc_with_padchest = [roc_auc_score(preds_df_tube['Endotracheal_tube_PadChest'], preds_df_tube['preds_Endo_model1']), roc_auc_score(preds_df_tube['Endotracheal_tube_PadChest'], preds_df_tube['preds_Endo_model2']), roc_auc_score(preds_df_tube['Endotracheal_tube_PadChest'], preds_df_tube['preds_Endo_model3'])]\n",
    "        print(\"Annotations Average auc:\", round(sum(auc_with_anns)/len(auc_with_anns)*100, 1), \"with standard deviation:\", round(statistics.stdev(auc_with_anns)*100,1))\n",
    "        print(\"PadChest Average auc:\", round(sum(auc_with_padchest)/len(auc_with_padchest)*100, 1), \"with standard deviation:\", round(statistics.stdev(auc_with_padchest)*100,1))\n",
    "        #print(auc_with_anns)\n",
    "        #print(auc_with_padchest)\n",
    "        print()\n",
    "\n",
    "        print('TRACHEOSTOMY TUBE')\n",
    "        preds_df_tube = preds_df[preds_df['Tracheostomy_tube_Ann'] != -1]\n",
    "        auc_with_anns = [roc_auc_score(preds_df_tube['Tracheostomy_tube_Ann'], preds_df_tube['preds_Trach_model1']), roc_auc_score(preds_df_tube['Tracheostomy_tube_Ann'], preds_df_tube['preds_Trach_model2']), roc_auc_score(preds_df_tube['Tracheostomy_tube_Ann'], preds_df_tube['preds_Trach_model3'])]\n",
    "        auc_with_padchest = [roc_auc_score(preds_df_tube['Tracheostomy_tube_PadChest'], preds_df_tube['preds_Trach_model1']), roc_auc_score(preds_df_tube['Tracheostomy_tube_PadChest'], preds_df_tube['preds_Trach_model2']), roc_auc_score(preds_df_tube['Tracheostomy_tube_PadChest'], preds_df_tube['preds_Trach_model3'])]\n",
    "        print(\"Annotations Average auc:\", round(sum(auc_with_anns)/len(auc_with_anns)*100, 1), \"with standard deviation:\", round(statistics.stdev(auc_with_anns)*100,1))\n",
    "        print(\"PadChest Average auc:\", round(sum(auc_with_padchest)/len(auc_with_padchest)*100, 1), \"with standard deviation:\", round(statistics.stdev(auc_with_padchest)*100,1))\n",
    "        #print(auc_with_anns)\n",
    "        #print(auc_with_padchest)\n",
    "        print()\n",
    "    \n",
    "    return preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468f9c13",
   "metadata": {},
   "source": [
    "### MultiTask: Pathology Detection - DenseNet121 (fine-tuned on PadChest), predictions on PadChest, detecting 5 pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76116677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effusion\n",
      "Average auc: 94.3 with standard deviation: 0.1\n",
      "\n",
      "Pneumothorax\n",
      "Average auc: 84.2 with standard deviation: 0.8\n",
      "\n",
      "Atelectasis\n",
      "Average auc: 86.8 with standard deviation: 0.3\n",
      "\n",
      "Cardiomegaly\n",
      "Average auc: 89.4 with standard deviation: 0.1\n",
      "\n",
      "Pneumonia\n",
      "Average auc: 80.1 with standard deviation: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_df = get_preds_multiclass_PD(MT_PD, padchest_test_labels_ALL)\n",
    "#preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d7b32c",
   "metadata": {},
   "source": [
    "### MultiTask: Tube Detection - DenseNet121 (fine-tuned on PadChest), predictions on PadChest, detecting 4 tubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "049c1146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHEST DRAIN TUBE\n",
      "Annotations Average auc: 35.7 with standard deviation: 5.2\n",
      "PadChest Average auc: 38.9 with standard deviation: 3.8\n",
      "\n",
      "NSG TUBE\n",
      "Annotations Average auc: 74.5 with standard deviation: 0.3\n",
      "PadChest Average auc: 69.8 with standard deviation: 0.9\n",
      "\n",
      "ENDOTRACHEAL TUBE\n",
      "Annotations Average auc: 66.2 with standard deviation: 1.6\n",
      "PadChest Average auc: 66.3 with standard deviation: 1.2\n",
      "\n",
      "TRACHEOSTOMY TUBE\n",
      "Annotations Average auc: 56.9 with standard deviation: 1.9\n",
      "PadChest Average auc: 56.9 with standard deviation: 1.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_df = get_preds_multiclass_TD(MT_TD, ann_labels)\n",
    "#preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b02e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7257aa5",
   "metadata": {},
   "source": [
    "## Implementation of Class-Wise Calibration Error (CWCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e6c2e",
   "metadata": {},
   "source": [
    "Binary Expected Calibration Error:\n",
    "$$ \\text{binary-ECE}  = \\sum_{i=1}^M \\frac{|B_{i}|}{N} |\n",
    "        \\bar{y}(B_{i}) - \\bar{p}(B_{i})| $$\n",
    "\n",
    "Class-wise Expected Calibration Error:\n",
    "$$ \\text{class-$j$-ECE}  = \\sum_{i=1}^M \\frac{|B_{i,j}|}{N}\n",
    "        |\\bar{y}_j(B_{i,j}) - \\bar{p}_j(B_{i,j})|,\n",
    "        \\text{classwise-ECE}  = \\frac{1}{K}\\sum_{j=1}^K \\text{class-$j$-ECE} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fdf0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_ECE(y_true, probs, power=1, bins=10):\n",
    "    r\"\"\"\n",
    "    Binary Expected Calibration Error\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : indicator vector (n_samples, )\n",
    "        True labels.\n",
    "    probs : matrix (n_samples, )\n",
    "        Predicted probabilities for positive class.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "    \"\"\"\n",
    "\n",
    "    create_bins = np.linspace(start=0, stop=1, num=bins + 1)   # Returns 'num' evenly spaced samples, calculated over the interval [start, stop]\n",
    "    #print('bins created: ', create_bins)\n",
    "    idx_bins = np.digitize(x=probs, bins=create_bins)   # Return the indices of the bins to which each value in input array belongs\n",
    "    idx_bins -= 1   # Need to subtract 1 from the bin indices to start at 0\n",
    "    \n",
    "    \n",
    "    # Function for computing the ECE for one bin\n",
    "    def bin_func(y, p, idx_bins):\n",
    "        probs_bin_mean = np.mean(p[idx_bins])   # Mean of probs in bin i\n",
    "        true_bin_mean = np.mean(y[idx_bins])   # Mean of true values in bin i\n",
    "        diff = np.abs(probs_bin_mean - true_bin_mean)   # Absolute difference between the two bin means\n",
    "        diff_power = diff ** power   # Raising the diff according to the L_p calibration error specified, typically power = 1\n",
    "        ece = diff_power * np.sum(idx_bins) / len(p)   # Multiplying by the fraction of probs in that bin\n",
    "        return ece\n",
    "        \n",
    "    # Computing the binary ECE for each bin and summing them\n",
    "    ece = 0\n",
    "    \n",
    "    for i in np.unique(idx_bins):   # Looping through the unique bins (len(bins))\n",
    "        ece += bin_func(y_true, probs, idx_bins == i)   # Summing the error for each bin\n",
    "\n",
    "    return ece\n",
    "\n",
    "\n",
    "def classwise_ECE(y_true, probs, classes_list, power=1, bins=10, print_ece=False):\n",
    "    r\"\"\"Classwise Expected Calibration Error\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : label indicator matrix (n_samples, n_classes)\n",
    "        True labels.\n",
    "    probs : matrix (n_samples, n_classes)\n",
    "        Predicted probabilities.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "    \"\"\"\n",
    "\n",
    "    n_classes = len(classes_list)\n",
    "    \n",
    "    # Computing the binary ECE for each class\n",
    "    class_eces = []\n",
    "    for c in range(n_classes):   # Looping through the classes\n",
    "        binary_ece = binary_ECE(y_true[:, c], probs[:, c], power=power, bins=bins)\n",
    "        if print_ece:\n",
    "            print('ECE for {}: {}'.format(classes_list[c], round(binary_ece, 3)))\n",
    "        class_eces.append(binary_ece)\n",
    "    \n",
    "    #if print_ece:\n",
    "        #print()\n",
    "        #print('Average Class-Wise ECE: ', round(np.mean(class_eces), 3))\n",
    "    \n",
    "    return class_eces\n",
    "    # Right now, not printing the average class-wise calibration error\n",
    "\n",
    "    \n",
    "def classwise_ECE_three_models_TD(df_orig, df_y_true, classes_list, power=1, bins=10):\n",
    "        \n",
    "    # Creating the preds df\n",
    "    preds_df = get_preds_multiclass_TD(df_orig, df_y_true, print_auc=False)\n",
    "    \n",
    "    all_model_eces_ann = []\n",
    "    all_model_eces_pad = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        probs_model_df = preds_df[['preds_CheD_model'+str(i+1), 'preds_NSG_model'+str(i+1), 'preds_Endo_model'+str(i+1), 'preds_Trach_model'+str(i+1)]]\n",
    "        y_true_ann_df = preds_df[['Chest_drain_Ann', 'NSG_tube_Ann', 'Endotracheal_tube_Ann', 'Tracheostomy_tube_Ann']]\n",
    "        y_true_pad_df = preds_df[['Chest_drain_tube_PadChest', 'NSG_tube_PadChest', 'Endotracheal_tube_PadChest', 'Tracheostomy_tube_PadChest']]\n",
    "        \n",
    "        class_eces_ann = classwise_ECE(y_true_ann_df.to_numpy(), probs_model_df.to_numpy(), classes_list=classes_list, power=power, bins=bins)\n",
    "        all_model_eces_ann.append(class_eces_ann)\n",
    "        \n",
    "        class_eces_pad = classwise_ECE(y_true_pad_df.to_numpy(), probs_model_df.to_numpy(), classes_list=classes_list, power=power, bins=bins)\n",
    "        all_model_eces_pad.append(class_eces_pad)\n",
    "        \n",
    "    #print(all_model_eces_ann)\n",
    "    #print(all_model_eces_pad)\n",
    "    \n",
    "    for c_idx, c in enumerate(classes_list):\n",
    "        print('Class: ', c)\n",
    "        print('Average CWCE Ann: ', round(sum([all_model_eces_ann[i][c_idx] for i in range(3)]) / 3, 5), 'with standard deviation: ', round(statistics.stdev([all_model_eces_ann[i][c_idx] for i in range(3)]), 5))\n",
    "        print('Average CWCE Pad: ', round(sum([all_model_eces_pad[i][c_idx] for i in range(3)]) / 3, 5), 'with standard deviation: ', round(statistics.stdev([all_model_eces_pad[i][c_idx] for i in range(3)]), 5))\n",
    "        print()\n",
    "    \n",
    "    return preds_df\n",
    "    # Right now, not printing the average class-wise calibration error\n",
    "\n",
    "    \n",
    "def classwise_ECE_three_models_PD(df_orig, df_y_true, classes_list, power=1, bins=10):\n",
    "        \n",
    "    # Creating the preds df\n",
    "    preds_df = get_preds_multiclass_PD(df_orig, df_y_true, print_auc=False)\n",
    "    \n",
    "    all_model_eces = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        probs_model_df = preds_df[['preds_Effusion_model'+str(i+1), 'preds_Pneumothorax_model'+str(i+1), 'preds_Atelectasis_model'+str(i+1), 'preds_Cardiomegaly_model'+str(i+1), 'preds_Pneumonia_model'+str(i+1)]]\n",
    "        y_true_ann_df = preds_df[['Effusion', 'Pneumothorax', 'Atelectasis', 'Cardiomegaly', 'Pneumonia']]\n",
    "        \n",
    "        class_eces = classwise_ECE(y_true_ann_df.to_numpy(), probs_model_df.to_numpy(), classes_list=classes_list, power=power, bins=bins)\n",
    "        all_model_eces.append(class_eces)\n",
    "        \n",
    "    #print(all_model_eces)\n",
    "    \n",
    "    for c_idx, c in enumerate(classes_list):\n",
    "        print('Class: ', c)\n",
    "        print('Average CWCE: ', round(sum([all_model_eces[i][c_idx] for i in range(3)]) / 3, 5), 'with standard deviation: ', round(statistics.stdev([all_model_eces[i][c_idx] for i in range(3)]), 5))\n",
    "        print()\n",
    "    \n",
    "    return preds_df\n",
    "    # Right now, not printing the average class-wise calibration error\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca30fde0",
   "metadata": {},
   "source": [
    "### MultiTask: Pathology Detection - DenseNet121 (fine-tuned on PadChest), predictions on PadChest, detecting 5 pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a11aa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  Effusion\n",
      "Average CWCE:  0.00808 with standard deviation:  0.00057\n",
      "\n",
      "Class:  Pneumothorax\n",
      "Average CWCE:  0.00018 with standard deviation:  0.00018\n",
      "\n",
      "Class:  Atelectasis\n",
      "Average CWCE:  0.0025 with standard deviation:  2e-05\n",
      "\n",
      "Class:  Cardiomegaly\n",
      "Average CWCE:  0.00633 with standard deviation:  0.00037\n",
      "\n",
      "Class:  Pneumonia\n",
      "Average CWCE:  0.00399 with standard deviation:  0.00123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pathologies = ['Effusion', 'Pneumothorax', 'Atelectasis', 'Cardiomegaly', 'Pneumonia']\n",
    "preds_df = classwise_ECE_three_models_PD(MT_PD, padchest_test_labels_ALL, classes_list=pathologies, power=1, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e4ca0d",
   "metadata": {},
   "source": [
    "### MultiTask: Tube Detection - DenseNet121 (fine-tuned on PadChest), predictions on PadChest, detecting 4 tubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdb8ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  Chest_drain_tube\n",
      "Average CWCE Ann:  0.01001 with standard deviation:  0.0019\n",
      "Average CWCE Pad:  0.05188 with standard deviation:  0.00113\n",
      "\n",
      "Class:  NSG_tube\n",
      "Average CWCE Ann:  0.21601 with standard deviation:  0.00694\n",
      "Average CWCE Pad:  0.3222 with standard deviation:  0.00373\n",
      "\n",
      "Class:  Endotracheal_tube\n",
      "Average CWCE Ann:  0.17787 with standard deviation:  0.00518\n",
      "Average CWCE Pad:  0.1839 with standard deviation:  0.00642\n",
      "\n",
      "Class:  Tracheostomy_tube\n",
      "Average CWCE Ann:  0.17213 with standard deviation:  0.00792\n",
      "Average CWCE Pad:  0.15868 with standard deviation:  0.00299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tube_types = ['Chest_drain_tube', 'NSG_tube', 'Endotracheal_tube', 'Tracheostomy_tube']\n",
    "preds_df = classwise_ECE_three_models_TD(MT_TD, ann_labels, classes_list=tube_types, power=1, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e188f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3c679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
