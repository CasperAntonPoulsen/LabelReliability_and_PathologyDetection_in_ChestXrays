Loaded module: cuda/12.2
2024-02-13 16:42:44.715348: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-02-13 16:42:44.753818: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-02-13 16:42:44.753883: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-02-13 16:42:44.754863: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-02-13 16:42:44.760396: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-02-13 16:42:45.889091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
  0%|          | 0/100 [00:00<?, ?it/s] 25%|██▌       | 25/100 [00:00<00:00, 239.92it/s] 49%|████▉     | 49/100 [00:00<00:00, 238.70it/s] 74%|███████▍  | 74/100 [00:00<00:00, 241.90it/s] 99%|█████████▉| 99/100 [00:00<00:00, 244.74it/s]100%|██████████| 100/100 [00:00<00:00, 243.07it/s]
2024-02-13 16:42:53.118416: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2024-02-13 16:42:53.154862: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2348] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer.
2024-02-13 16:42:53.551248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78750 MB memory:  -> device: 0, name: NVIDIA H100 PCIe, pci bus id: 0000:41:00.0, compute capability: 9.0
Skipping variable loading for optimizer 'adam', because it has 730 variables whereas the saved optimizer has 22 variables. 
Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.
2024-02-13 16:43:18.711860: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902
Traceback (most recent call last):
  File "/dtu/p1/johlau/LabelReliability_and_PathologyDetection_in_ChestXrays/ObjectDetection/calculate_shap.py", line 80, in <module>
    e = shap.DeepExplainer(model, background)
  File "/zhome/4e/b/208805/.local/lib/python3.9/site-packages/shap/explainers/_deep/__init__.py", line 84, in __init__
    self.explainer = TFDeep(model, data, session, learning_phase_flags)
  File "/zhome/4e/b/208805/.local/lib/python3.9/site-packages/shap/explainers/_deep/deep_tf.py", line 173, in __init__
    noutputs = self.model_output.shape.as_list()[1]
AttributeError: 'tuple' object has no attribute 'as_list'
